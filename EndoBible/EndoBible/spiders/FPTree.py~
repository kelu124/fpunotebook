from scrapy.spider import BaseSpider
from scrapy.selector import HtmlXPathSelector
from scrapy.http import Request
from scrapy.utils.url import urljoin_rfc
from scrapy.utils.response import get_base_url

import re

#all_links = hxs.select('//a/@href').extract()
#abs_links = [urljoin_rfc(get_base_url(response), x) for x in all_links]

from EndoBible.items import FPTree_Item

class FPTree(BaseSpider):
	name = "FPTree"
	allowed_domains = ["fpnotebook.com"]
	start_urls = [
		"http://www.fpnotebook.com/Endo/Adrenal/Phchrmcytm.htm"
	]


# NOW ENTERING THE CHAPTER LIST
	def parse(self, response):
		p = re.compile(r'<.*?>')
		hxs = HtmlXPathSelector(response)
		items = []
		Titre = hxs.select("//h2/text()").extract()
		GrosTitres = hxs.select("//div[@id='mainContent_text']//parent::li")
		for GrosTitre in GrosTitres:
			item = FPTree_Item()
			Upper =  GrosTitre.select("../..")
			item['FPT_Page'] = "".join(Titre)
			item['FPT_URL'] = response.url
			if 'mainContent_text' in  " ".join(Upper.extract()): item['FPT_Parent_name'] = "".join(Titre)
			if not 'mainContent_text' in  " ".join(Upper.extract()): item['FPT_Parent_name'] = p.sub('', Upper.re('<li>(.*?)<ol>')[0])

			#if not "<ol>" in "".join(GrosTitre.extract()): item['FPT_Name'] = "".join(GrosTitre.extract())
 			#if "<ol>" in "".join(GrosTitre.extract()): item['FPT_Name'] = GrosTitre.re('<li>(.*?)<ol>')[0]
			if not "<ol>" in "".join(GrosTitre.extract()): item['FPT_Name'] = p.sub('', "".join(GrosTitre.extract()) )
 			if "<ol>" in "".join(GrosTitre.extract()): item['FPT_Name'] = p.sub('', GrosTitre.re('<li>(.*?)<ol>')[0] )


			items.append(item)
		return items



